{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep reinforcement learning algorithm\n",
    "\n",
    "## Table of contents:\n",
    "* [Robot environment](#robot_environment)\n",
    "* [Convolutional neural network](#cnn)\n",
    "* [Plotting](#plot)\n",
    "* [Training](#training)\n",
    "\n",
    "## Robot environment <a class=\"anchor\" id=\"robot_environment\"></a>\n",
    "\n",
    "A `EnvRobot` class was developped to simplify exchanges between the reinforcement learning script and the server.\n",
    "It allows to :\n",
    "+ Initialize the robot environment\n",
    "+ Reset the robot environment\n",
    "+ Give an order to the robot (up, down, left...)\n",
    "+ Recover information from the robot (camera, position, senors...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Initialization\n",
    "\n",
    "1. **Start** the server\n",
    "2. Initialize all variables related to the **server**\n",
    "3. Initialize all variables related the **camera and sensors**\n",
    "4. Initialize all variables related the **simulation**\n",
    ">+ **`step_size`** : size of a robot step\n",
    ">+ **`angle`** : limits of the robot angle <br>(ex : if `angle` = 20, 20° to the left, 20° to the right)\n",
    ">+ **`height_max`/`height_min`** : limits of the height robot <br>(to find values : test with the `manual` stcript)\n",
    ">+ **`time_size`** : time for a step robot\n",
    ">+ **`total_step`** : total step in 1 episode\n",
    ">+ **`reward_step`** : reward for each step\n",
    ">+ **`reward_win`/`reward_lose`** : reward when the robot acheived the goal/crash into the limits\n",
    ">+ **`reward_pixel_max`** : maximum reward for red pixels <br>(ex : if `reward_pixel_max = 30` and the red cube take `10%` of the image, the reward for red pixels will be `3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start server\n",
    "self.server = tcp_server()\n",
    "ip, port = get_server_settings()\n",
    "self.server.connect(ip, port)\n",
    "\n",
    "#Attributes initialization\n",
    "\n",
    "#For interaction with the server\n",
    "self.base               = 0.0\n",
    "self.lnk1               = 69.0\n",
    "self.lnk2               = -85.0\n",
    "self.time               = 1.0\n",
    "self.reset              = False\n",
    "self.camera             = None\n",
    "self.actual_position    = None\n",
    "self.target_position    = None\n",
    "\n",
    "#Camera size\n",
    "self.camera_width = 256\n",
    "self.camera_height = 256\n",
    "\n",
    "#Sensors\n",
    "self.sensor_up          = 0.0\n",
    "self.sensor_down        = 0.0\n",
    "self.sensor_left        = 0.0\n",
    "self.base_left          = 0.0\n",
    "self.sensor_right       = 0.0\n",
    "self.base_right         = 0.0\n",
    "\n",
    "#Simulation parameters\n",
    "self.step_size          = 4\n",
    "self.angle              = 20\n",
    "self.height_max         = 21.0\n",
    "self.height_min         = 7.0\n",
    "self.time_size          = 0.000001\n",
    "self.total_step         = total_step\n",
    "self.reward_step        = -0.5\n",
    "self.reward_win         = 200 \n",
    "self.reward_lose        = -200\n",
    "self.reward_pixel_max   = 30.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reset\n",
    "\n",
    "1. **Reset** all variables related to the server\n",
    "2. **Pack** these data for server\n",
    "3. **Send** this package to the server\n",
    "4. **Updtate** all variables related to the server\n",
    "5. **Reset** the state (image and sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def res(self, reset_cube=False):\n",
    "\n",
    "    #Reset function\n",
    "    self.base               = 0.0\n",
    "    self.lnk1               = 69.0\n",
    "    self.lnk2               = -85.0\n",
    "    self.time               = 0.00001\n",
    "    self.reset              = reset_cube\n",
    "    self.camera             = None\n",
    "    self.actual_position    = None\n",
    "    self.target_position    = None\n",
    "    data_to_server = (0.0,0.0,0.0,0.0,False)\n",
    "    data_to_server = list(data_to_server)\n",
    "    data_to_server[0] = self.time\n",
    "    data_to_server[1] = self.base   \n",
    "    data_to_server[2] = self.lnk1   \n",
    "    data_to_server[3] = self.lnk2\n",
    "    data_to_server[4] = self.reset\n",
    "    data_to_server = tuple(data_to_server)\n",
    "    to_server(self.server,data_to_server)\n",
    "    data_from_server = from_server(self.server)\n",
    "\n",
    "    self.camera          = data_from_server[0]\n",
    "    self.actual_position = data_from_server[1]\n",
    "    self.target_position = data_from_server[2]\n",
    "    self.base            = data_from_server[3]\n",
    "    self.lnk1            = data_from_server[4]\n",
    "    self.lnk2            = data_from_server[5]\n",
    "    self.time = 1.0\n",
    "    self.reset = False\n",
    "\n",
    "    img = np.array(self.camera.resize((84,84), Image.ANTIALIAS))\n",
    "    sensors = np.array([0,0,0,0])\n",
    "    state = np.array([img, sensors])\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step\n",
    "\n",
    "First, we **update** all variables related to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Robot data reception from the server\n",
    "data_from_server = from_server(self.server)\n",
    "self.camera          = data_from_server[0]\n",
    "self.actual_position = data_from_server[1]\n",
    "self.target_position = data_from_server[2]\n",
    "self.base            = data_from_server[3]\n",
    "self.lnk1            = data_from_server[4]\n",
    "self.lnk2            = data_from_server[5]\n",
    "self.time = self.time_size\n",
    "self.reset = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now **calculate the next order** for the robot with the function `do_action`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate the new position from the action\n",
    "self.base, self.lnk1, self.lnk2 = do_action(action, self.base, self.lnk1, self.lnk2, self.step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`do_action` take in argument :\n",
    "+ the **action to do**\n",
    "+ the **position of the robot**\n",
    "+ the **step size**\n",
    "It retuns :\n",
    "+ the** movement to be perfomed** by the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_action(action, base, lnk1, lnk2, step):\n",
    " \n",
    "    if action == 0:\n",
    "        base += step #Base+\n",
    "    elif action == 1:\n",
    "        base -= step #Base-\n",
    "    elif action == 2:        \n",
    "        lnk1 += step #Lnk1+\n",
    "    elif action == 3:\n",
    "        lnk1 -= step #Lnk1-\n",
    "    elif action == 4:\n",
    "        lnk2 += step #Lnk2+\n",
    "    elif action == 5:\n",
    "        lnk2 -= step #Lnk2-\n",
    "    elif action == 6:\n",
    "        base += step #Base+,Lnk1+\n",
    "        lnk1 += step\n",
    "    elif action == 7:\n",
    "        base += step #Base+,Lnk1-\n",
    "        lnk1 -= step\n",
    "    elif action == 8:\n",
    "        base -= step #Base-,Lnk1+\n",
    "        lnk1 += step\n",
    "    elif action == 9:\n",
    "        base -= step #Base-,Lnk1-\n",
    "        lnk1 -= step\n",
    "    elif action == 10:\n",
    "        base += step #Base+,Lnk2+\n",
    "        lnk2 += step\n",
    "    elif action == 11:\n",
    "        base += step #Base+,Lnk2-\n",
    "        lnk2 -= step\n",
    "    elif action == 12:\n",
    "        base -= step #Base-,Lnk2+\n",
    "        lnk2 += step\n",
    "    elif action == 13:\n",
    "        base -= step #Base-,Lnk2-\n",
    "        lnk2 -= step\n",
    "    elif action == 14:\n",
    "        lnk1 += step #Lnk1+, Lnk2+\n",
    "        lnk2 += step\n",
    "    elif action == 15:\n",
    "        lnk1 += step #Lnk1+, Lnk2-\n",
    "        lnk2 -= step\n",
    "    elif action == 16:\n",
    "        lnk1 -= step #Lnk1-, Lnk2+\n",
    "        lnk2 += step\n",
    "    elif action == 17:\n",
    "        lnk1 -= step #Lnk1-, Lnk2-\n",
    "        lnk2 -= step\n",
    "    elif action == 18:\n",
    "        base += step # Base+, Lnk1+, Lnk2+\n",
    "        lnk1 += step\n",
    "        lnk2 += step\n",
    "    elif action == 19:\n",
    "        base += step # Base+, Lnk1+, Lnk2-\n",
    "        lnk1 += step\n",
    "        lnk2 -= step\n",
    "    elif action == 20:\n",
    "        base += step # Base+, Lnk1-, Lnk2+\n",
    "        lnk1 -= step\n",
    "        lnk2 += step\n",
    "    elif action == 21:\n",
    "        base += step # Base+, Lnk1-, Lnk2-\n",
    "        lnk1 -= step\n",
    "        lnk2 -= step\n",
    "    elif action == 22:\n",
    "        base -= step # Base-, Lnk1+, Lnk2+\n",
    "        lnk1 += step\n",
    "        lnk2 += step\n",
    "    elif action == 23:\n",
    "        base -= step # Base-, Lnk1+, Lnk2-\n",
    "        lnk1 += step\n",
    "        lnk2 -= step\n",
    "    elif action == 24:\n",
    "        base -= step # Base-, Lnk1-, Lnk2+\n",
    "        lnk1 -= step\n",
    "        lnk2 += step\n",
    "    elif action == 25:\n",
    "        base -= step # Base-, Lnk1-, Lnk2-\n",
    "        lnk1 -= step\n",
    "        lnk2 -= step\n",
    "    else:\n",
    "        print(\"[ERROR] The action %d doesn't exist\" % action)\n",
    "\n",
    "    return base, lnk1, lnk2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to move the robot.\n",
    "1. **Send** the movement to the robot\n",
    "2. **Update** the new position\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE</b> After sending the data to the server, it's obligatory to receive the feedback.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Send the action to the server\n",
    "data_to_server = (0.0,0.0,0.0,0.0,False)\n",
    "data_to_server = list(data_to_server)\n",
    "data_to_server[0] = self.time\n",
    "data_to_server[1] = self.base   \n",
    "data_to_server[2] = self.lnk1   \n",
    "data_to_server[3] = self.lnk2\n",
    "data_to_server[4] = self.reset\n",
    "data_to_server = tuple(data_to_server)\n",
    "to_server(self.server,data_to_server)\n",
    "\n",
    "\n",
    "#Update attributes from the server\n",
    "data_from_server = from_server(self.server)\n",
    "self.camera          = data_from_server[0]\n",
    "self.actual_position = data_from_server[1]\n",
    "self.target_position = data_from_server[2]\n",
    "self.base            = data_from_server[3]\n",
    "self.lnk1            = data_from_server[4]\n",
    "self.lnk2            = data_from_server[5]\n",
    "self.time = self.time_size\n",
    "self.reset = False\n",
    "data_to_server = (0.0,0.0,0.0,0.0,False)\n",
    "data_to_server = list(data_to_server)\n",
    "data_to_server[0] = 0.0\n",
    "data_to_server[1] = self.base   \n",
    "data_to_server[2] = self.lnk1   \n",
    "data_to_server[3] = self.lnk2\n",
    "data_to_server[4] = self.reset\n",
    "data_to_server = tuple(data_to_server)\n",
    "to_server(self.server,data_to_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can **process** the received data to obtain environment observations.<br>\n",
    "First, we **calculate** the value of our virtual sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Virtual sensors (Robot point of view)\n",
    "self.sensor_up = self.height_max - self.actual_position.y\n",
    "self.sensor_down = self.actual_position.y - self.height_min\n",
    "if self.base <= 180:\n",
    "    self.sensor_left = self.angle - self.base\n",
    "    self.sensor_right = self.angle + self.base\n",
    "else:\n",
    "    self.sensor_left = self.angle + (360 - self.base)\n",
    "    self.sensor_right = self.base - (360 - self.angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after, we **exploit** camera data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Camera resizing for covnet\n",
    "img = np.array(self.camera.resize((84,84), Image.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have now **our current state**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensors = np.array([self.sensor_up, self.sensor_down, self.sensor_left, self.sensor_right])\n",
    "state = np.array([img, sensors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know if **the current episode is finished or not** (crash or achieved goal), we **fix some conditions** about limits in space and red pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Movement\n",
    "left_done = bool(self.sensor_left <= -self.step_size)\n",
    "right_done = bool(self.sensor_right <= -self.step_size)\n",
    "up_done = bool(self.sensor_up <= -1)\n",
    "down_done = bool(self.sensor_down <= -1)\n",
    "lnk1_done = bool(self.lnk1 > 90.0)\n",
    "\n",
    "#Camera pixel\n",
    "red_pixel_camera = red_pixel(self.camera)                   #0 to 65536\n",
    "red_pixel_camera /= self.camera_width * self.camera_height  #0 to 1\n",
    "red_pixel_camera *= self.reward_pixel_max                   #ex: 0 to 30\n",
    "\"\"\"red_pixel_camera -= 0.5                                  #-0.5 to 0.5\n",
    "red_pixel_camera *= self.reward_pixel_max*2                 #ex : -30 to 30\"\"\"\n",
    "pixel_done = bool(red_pixel_camera == self.reward_pixel_max)\n",
    "\n",
    "done = left_done or right_done or up_done or down_done or lnk1_done or pixel_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we calculate the **current stqte reward** and return all **step observations**.<br>\n",
    "If the episode is not finished : `reward = reward for each step + reward from the camera`<br>\n",
    "If the episode is finished, we **test if the goal is achieved** and we **calculate the corresponding reward**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not done:\n",
    "    #Continue\n",
    "\n",
    "    #Reward calculation\n",
    "    reward = self.reward_step + red_pixel_camera\n",
    "else:\n",
    "    #Finish\n",
    "    if pixel_done:\n",
    "        #Achived goal\n",
    "        reward = self.reward_win\n",
    "    else:\n",
    "        #Fail / Crash\n",
    "        reward = self.reward_lose\n",
    "\n",
    "return state, reward, done, pixel_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network <a class=\"anchor\" id=\"cnn\"></a>\n",
    "\n",
    "A `ConvolutionalNeuralNetwork` class was developped to implement the CNN in charge of the action decision.\n",
    "It's inspired by _DeepMind_ convolutionnal neural network.\n",
    "\n",
    "<img style=\"float: center;\" src=\"../../Misc/CNN.png\">\n",
    "<img style=\"float: center;\" src=\"../../Misc/Tab.png\">\n",
    "\n",
    "\n",
    "##### Initialization\n",
    "First we define networks parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input image size\n",
    "self.img_x = 84\n",
    "self.img_y = 84\n",
    "self.img_channel = 3\n",
    "\n",
    "#Network Parameters \n",
    "self.n_image = self.img_x * self.img_y  # data input (img shape: 84*84)\n",
    "self.n_classes = 26                     # total classes (actions)\n",
    "self.dropout = 0.75                     # Dropout, probability to keep units\n",
    "self.learning_rate=0.003                #Learning rate to update covnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the inputs/outputs placeholders.\n",
    "<br><br>\n",
    "_INPUT_\n",
    "+ **input_image**: 84x84x3 float\n",
    "+ **keep_prob**: 1 float (0 ≤ keep_prob < 1)\n",
    "+ **reward_holder**: 1 float \n",
    "+ **action_holder**: 1 int (0 ≤ action_holder < 27)\n",
    "+ **sensors**: 4 float [up, down, left, right]\n",
    "\n",
    "_OUTPUT_\n",
    "+ **Q**: 26 float (action prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Covnet input\n",
    "#Input image (84x84x3)\n",
    "self.input_image = tf.placeholder(tf.float32, [None, self.img_x, self.img_y, self.img_channel])\n",
    "#Dropout (keep probability)\n",
    "self.keep_prob = tf.placeholder(tf.float32)\n",
    "#Obtained reward\n",
    "self.reward_holder = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "#Achieved action\n",
    "self.action_holder = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "#Sensors\n",
    "self.sensors = tf.placeholder(shape=[None,4],dtype=tf.float32)\n",
    "#Covnet output\n",
    "self.Q = tf.placeholder(tf.float32, [None, self.n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize :\n",
    "+ **weights** with normal repartition\n",
    "+ **biases** with ones (and zeros for the last layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Store layers weight & bias\n",
    "self.weights = {\n",
    "    # 8x8 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.truncated_normal([8, 8, 3, 32], 0.0)),\n",
    "    # 4x4 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.truncated_normal([4, 4, 32, 64], 0.0)),\n",
    "    # 3x3 conv, 64 inputs, 64 ones\n",
    "    'wc3': tf.Variable(tf.truncated_normal([3, 3, 64, 64], 0.0)),\n",
    "    # fully connected, 7*7*64 inputs, 512 outputs\n",
    "    'wd1': tf.Variable(tf.truncated_normal([7*7*64, 512], 0.0)),\n",
    "    # 516 inputs, 26 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.truncated_normal([516, self.n_classes]))\n",
    "}\n",
    "\n",
    "self.biases = {\n",
    "    'bc1': tf.Variable(tf.ones([32])),\n",
    "    'bc2': tf.Variable(tf.ones([64])),\n",
    "    'bc3': tf.Variable(tf.ones([64])),\n",
    "    'bd1': tf.Variable(tf.ones([512])),\n",
    "    'out': tf.Variable(tf.zeros([self.n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creation\n",
    "\n",
    "We create a function to create our CNN.\n",
    "1. Reshape the image to **84x84x3**\n",
    "2. Create **3 convolution layers**\n",
    "3. Create the **full connected layer**\n",
    "4. Apply a **dropout** to avoid overfitting\n",
    "5. Add the **sensors value**\n",
    "6. Calculate the **output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv_net(self, x, weights, biases, dropout):\n",
    "\n",
    "    #DeepMind Neural Network\n",
    "    #https://www.intelnervana.com/demystifying-deep-reinforcement-learning/\n",
    "\n",
    "    print(\"\\nConvolutional neural network characteristic :\")\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, self.img_x, self.img_y, 3])\n",
    "    print(\"Input      : \", x._shape)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'], 4)\n",
    "    print(\"Conv 1     : \", conv1._shape)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'], 2)\n",
    "    print(\"Conv 2     : \", conv2._shape)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'], 1)\n",
    "    print(\"Conv 3     : \", conv3._shape)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    print(\"Reshape    : \", fc1.shape)\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    print(\"Calculate  : \", fc1.shape)\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    print(\"Relu       : \", fc1.shape)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    print(\"Dropout    : \", fc1.shape)\n",
    "    fc1 = tf.concat([fc1,self.sensors],1)\n",
    "    print(\"Merge      : \", fc1.shape)\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    print(\"Out        : \", out.shape)\n",
    "    print(\"\\n\")\n",
    "    return out\n",
    "        \n",
    "\n",
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')\n",
    "    x = tf.nn.bias_add(x, b)    \n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to construct our forward graph.\n",
    "1. **Normalization** : pixel are converted from integer between 0 to 255 to float between -1 and 1\n",
    "2. **Forwarding** : with our function conv_net\n",
    "3. **Calculating softmax** : to obtain percentage of each action\n",
    "4. **Calculating argmax** : to obtain the max of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalization : 0 to 255 => -1 to 1\n",
    "self.input_image = tf.multiply(tf.subtract(tf.scalar_mul((1.0/255.0), self.input_image),0.5),2.0) \n",
    "\n",
    "#Select action\n",
    "#Covnet\n",
    "self.Q = self.conv_net(self.input_image, self.weights, self.biases, self.keep_prob)\n",
    "#Softmax function\n",
    "self.soft = tf.nn.softmax(self.Q)\n",
    "#Maximum argument of softmax\n",
    "self.chosen_action = tf.argmax(self.soft,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after, we create our updating graph.\n",
    "1. Find the **weight of the achieved action** in the output layer\n",
    "2. Calculate the **loss** (`-log(π)*A`)\n",
    "3. **Optimize our model** with a specified learning rate (usually between 0.1 and 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Responsible weight finding thanks to the achieved action\n",
    "self.responsible_weight = tf.slice(self.Q[0],self.action_holder,[1])\n",
    "#Loss calculation : -(log(responsible_weight) * reward_holder)\n",
    "self.log = tf.log(self.responsible_weight)\n",
    "self.loss = -(self.log*self.reward_holder)\n",
    "#Optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "self.updateModel = optimizer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is ready to be created !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting <a class=\"anchor\" id=\"plot\"></a>\n",
    "\n",
    "A `PlotReward` class was developped **to plot the results in a graph**.\n",
    "\n",
    "##### Initialization\n",
    "\n",
    "First, we **recover the name of the simulation** placed in argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self.simulation_name = simulation_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **define our data list** for each family results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Abcissa\n",
    "self.xdata = []\n",
    "#Ordinates\n",
    "self.ydata = []\n",
    "self.y2data = []\n",
    "self.y3data = []\n",
    "self.y4data = []\n",
    "self.y5data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize plot parameters.\n",
    "+ **nb_done** : number of achieved goal\n",
    "+ **nb_crash** : number of crash\n",
    "+ **nb_fail** : number of fail (the robot don't achieved the goal without crash)\n",
    "+ **nb_episodes** : number of episodes\n",
    "+ **destination** : destionation where the graph will be saved\n",
    "+ **nb_filename** : find the name of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialization\n",
    "self.nb_done = 0\n",
    "self.nb_crash = 0\n",
    "self.nb_fail = 0\n",
    "self.nb_episode = 0\n",
    "self.destination = \"save/plot/\"\n",
    "self.nb_filename = find_name(self.destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_name` function **returns the graph number** (ex : reward(?).png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the name of the plot for saving : reward(?).png\n",
    "def find_name(destination):\n",
    "    done = False\n",
    "    i=0\n",
    "    while(not(done)):\n",
    "        if os.path.isfile(destination + 'reward(' + str(i) + ').png'):\n",
    "            i += 1\n",
    "        else:\n",
    "            done = True\n",
    "    return str(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we **create our graph**.\n",
    "\n",
    "1. **Create** the windows \n",
    "2. **Add** the name of the simulation in windows title\n",
    "3. **Format** the graph\n",
    "4. **Add** labels and graph title\n",
    "5. **Create** our curves and points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create plot windows\n",
    "plt.figure(figsize=(8,7), num=self.simulation_name)\n",
    "\n",
    "#Add a suptittle\n",
    "plt.suptitle(self.simulation_name, fontsize=14, fontweight='bold')\n",
    "\n",
    "#Select windows\n",
    "self.axes_reward = plt.gca()\n",
    "#Shrink graph size for the legend\n",
    "box = self.axes_reward.get_position()\n",
    "self.axes_reward.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "self.axes_reward.set_title('Reward for each episode')\n",
    "#Abcissa & ordinates labels\n",
    "self.axes_reward.set_xlabel('Episode')\n",
    "self.axes_reward.set_ylabel('Reward ')\n",
    "#Create curves \n",
    "self.line, = self.axes_reward.plot(self.xdata, self.ydata, color='silver', label='Reward')\n",
    "self.line2, = self.axes_reward.plot(self.xdata, self.y2data, linestyle='dotted', color='black', label='Average')\n",
    "self.point, = self.axes_reward.plot(self.xdata, self.y3data, linestyle='None', marker='o', markerfacecolor='g', markeredgewidth=0.0, label='Done')\n",
    "self.point2, = self.axes_reward.plot(self.xdata, self.y4data, linestyle='None', marker='o', markerfacecolor='r', markeredgewidth=0.0, label='Crash')\n",
    "self.point3, = self.axes_reward.plot(self.xdata, self.y5data, linestyle='None', marker='o', markerfacecolor='orange', markeredgewidth=0.0, label='Fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot\n",
    "\n",
    "First, we **update all values** of our graph.\n",
    "1. **Curves** values (episode reward and average reward)\n",
    "2. **Points** values (done, fail and crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add values to the graph\n",
    "self.xdata.append(episode)\n",
    "self.ydata.append(data[episode])\n",
    "self.y2data.append(avg_reward[episode])\n",
    "\n",
    "#Add value for \"Done\" or \"Crash\" or \"Fail\"\n",
    "if pixel_done:\n",
    "    self.y3data.append(data[episode])\n",
    "    self.nb_done += 1\n",
    "else:\n",
    "     self.y3data.append(None)\n",
    "if done and not(pixel_done):\n",
    "    self.y4data.append(data[episode])\n",
    "    self.nb_crash += 1\n",
    "else:\n",
    "     self.y4data.append(None)\n",
    "if not(done) and not(pixel_done):\n",
    "    self.y5data.append(data[episode])\n",
    "    self.nb_fail += 1\n",
    "else:\n",
    "     self.y5data.append(None)\n",
    "\n",
    "\n",
    "#Counting the number of episodes\n",
    "self.nb_episode += 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now **add the new values to the graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update graph values\n",
    "self.line.set_xdata(self.xdata)\n",
    "self.line.set_ydata(self.ydata)\n",
    "self.line2.set_xdata(self.xdata)\n",
    "self.line2.set_ydata(self.y2data)\n",
    "self.point.set_xdata(self.xdata)\n",
    "self.point.set_ydata(self.y3data)\n",
    "self.point2.set_xdata(self.xdata)\n",
    "self.point2.set_ydata(self.y4data)\n",
    "self.point3.set_xdata(self.xdata)\n",
    "self.point3.set_ydata(self.y5data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **adjust the limit of the graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update the limit of the graf in function of graph values\n",
    "self.axes_reward.set_xlim(0, episode+1)\n",
    "self.axes_reward.set_ylim(worst_reward - 10, best_reward + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **plot the corresponding legend** with percentages of done, fail and crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update legend\n",
    "plt.legend([self.line, self.line2, self.point, self.point3, self.point2], ['Reward', 'Average', 'Done (%.2f%%)' % ((self.nb_done/self.nb_episode)*100), 'Fail (%.2f%%)' % ((self.nb_fail/self.nb_episode)*100), 'Crash (%.2f%%)' % ((self.nb_crash/self.nb_episode)*100)], loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally **we draw and save the graph**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.draw()\n",
    "#Save the graph\n",
    "plt.savefig(self.destination + 'reward('+ self.nb_filename +').png')\n",
    "plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training <a class=\"anchor\" id=\"training\"></a>\n",
    "\n",
    "For the moment, we can interact with our robot environement, use our CNN and plot the results.<br>\n",
    "Let's start **to create a training** for our robot !\n",
    "\n",
    "##### Initialization\n",
    "\n",
    "We define and intialize simulation parameters.\n",
    "\n",
    "+ **total_episode** : number of episode in the training\n",
    "+ **total_step** : number of step in each episode\n",
    "+ **best_episode_reward** : information to know the best reward in an episode\n",
    "+ **best_reward** : information to know the best episode reward in the training\n",
    "+ **worst_reward** : information the know the worst episode reward in the training\n",
    "+ **avg_reward** : information the know the average reward in the training\n",
    "+ **e** (epsilon) : percentage to do a random action\n",
    "+ **pixel_done** : True if the goal is achieved\n",
    "+ **reset_crash** : reset red cube position after n crash\n",
    "+ **nb_pixel_crash** : counter for the number of crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simulation parameters\n",
    "total_episodes = 1000\n",
    "total_step = 30\n",
    "best_episode_reward = 0.0\n",
    "best_reward = -1000\n",
    "worst_reward = 1000\n",
    "avg_reward = 0.0\n",
    "e = 0.1\n",
    "pixel_done = False\n",
    "reset_crash = False\n",
    "nb_pixel_crash = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **create the robot environment** thanks to the `EnvRobot` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Robot environement creation\n",
    "env = EnvRobot(total_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reset, create and initialize our CNN thanks to the `ConvolutionalNeuralNetwork` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TensorFlow graph\n",
    "tf.reset_default_graph() \n",
    "cnn = ConvolutionalNeuralNetwork() #Load the convolutional neural network\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the possibility **to save or restore** a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To save the Tensorflow graph\n",
    "saver = tf.train.Saver()\n",
    "restore_destination = \"save/checkpoint/restore/\"\n",
    "saver_destination = find_folder(\"save/checkpoint/trained/\")\n",
    "\n",
    "#Find the name of the folder for saving model + create folder: simulation(?)\n",
    "def find_folder(destination):\n",
    "    done = False\n",
    "    i=0\n",
    "    while(not(done)):\n",
    "        if os.path.isdir(destination + 'simulation(' + str(i) + ')'):\n",
    "            i += 1\n",
    "        else:\n",
    "            os.makedirs(destination + 'simulation(' + str(i) + ')')\n",
    "            path = destination + 'simulation(' + str(i) + ')/'\n",
    "            done = True\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define plot parameters.<br>\n",
    "There is two curves :\n",
    "+ the reward for each episode\n",
    "+ the average reward in the simulation\n",
    "\n",
    "And we ***create our graph figure***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot parameters\n",
    "plot_reward = np.empty([total_episodes])\n",
    "plot_avg_reward = np.empty([total_episodes])\n",
    "fig = PlotReward(saver_destination.split(\"/\")[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running\n",
    "\n",
    "It's time to **launch the TensorFlow graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask to the user if he **wants to restore a session**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Restore a model\n",
    "restore = prompt('\\nRestore session (y/ n): ', 'y')\n",
    "if restore == 'y':\n",
    "    saver.restore(sess, restore_destination + \"model.ckpt\")\n",
    "    print(\"The model was successfully restored !\")\n",
    "else:\n",
    "    print(\"No model has been restored !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We launch a timer to calculate **the duration of the simulation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_start = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is ready ! <br>\n",
    "Let's **start the simulation** of n episodes !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Episode loop\n",
    "for x in range(total_episodes):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each episode, we **reset the environment**.\n",
    "+ **done** : True if the espisode is finished\n",
    "+ **running_reward** : episode reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset the environement\n",
    "reset_cube = pixel_done or reset_crash\n",
    "state = env.res(reset_cube=reset_cube)\n",
    "reset_crash = False\n",
    "done = False\n",
    "running_reward = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **start the episode** of n steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step loop\n",
    "for i in range(total_step):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our CNN to **predict the action to do**.\n",
    "> We feed our TensorFlow graph with :\n",
    ">+ **`state[0]`** : the camera\n",
    ">+ **`state[1]`** : the sensors\n",
    ">+ **cnn.dropout** : the droupout (between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Choose action from camera with the covnet\n",
    "#input_image    : camera\n",
    "#keep_prob      : dropout (if 0.75, 75% chance to keep the neuron)\n",
    "#Q              : output of the last fully connected layer of the covnet\n",
    "#soft           : softmax function from Q values\n",
    "#action         : chosen action\n",
    "Q, soft, action = sess.run([cnn.Q, cnn.soft, cnn.chosen_action], feed_dict={cnn.input_image:[state[0]], cnn.sensors:[state[1]], cnn.keep_prob:[cnn.dropout]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we add the random action thanks to epsilon.\n",
    ">`action = action[0]` : TensorFlow returns an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Action choice (with e chance of random action)\n",
    "rdm = np.random.rand(1)\n",
    "if  rdm < e:\n",
    "    action = random.randint(0, cnn.n_classes-1)\n",
    "    print(\"Random action    : %d (%s)\" % (action, action_name(action)))    \n",
    "else:\n",
    "    action = action[0]\n",
    "    print(\"Chosen action    : %d (%s)\" % (action, action_name(action)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **do the action** thanks to the `step` function.<br>\n",
    "We **recover observations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step with the action + informations recovery\n",
    "#action     : chosen action\n",
    "#state1     : next state\n",
    "#reward     : reward value\n",
    "#done       : true if the simulation is finished \n",
    "#pixel_done : true if the camera is composed of only red pixels\n",
    "state1, reward, done, pixel_done = env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can **update our covnet**.\n",
    ">We feed TensorFlow graph with :\n",
    ">+ **`state[0]`** : the camera\n",
    ">+ **`state[1]`** : the sensors\n",
    ">+ **cnn.dropout** : the droupout (between 0 and 1)\n",
    ">+ **reward** : step reward\n",
    ">+ **action** : achived action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update the covnet\n",
    "#input_image    : camera\n",
    "#keep_prob      : dropout (if 0.75, 75% chance to keep the neuron)\n",
    "#reward_holder  : obtained reward\n",
    "#action_holder  : achieved action\n",
    "#resp           : responsible weight\n",
    "#log            : log(resp)\n",
    "#loss           : calculated loss => -(log(resp) * reward_holder)\n",
    "_,resp, log, loss = sess.run([cnn.updateModel,cnn.responsible_weight, cnn.log, cnn.loss], feed_dict={cnn.input_image:[state[0]], cnn.sensors:[state[1]], cnn.keep_prob:[cnn.dropout], cnn.reward_holder:[reward], cnn.action_holder:[action]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **update also the state**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Update the state\n",
    "state = state1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the **episode reward** and the **best episode reward**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Best reward calculation\n",
    "running_reward += reward\n",
    "if running_reward > best_episode_reward:\n",
    "        best_episode_reward = running_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the simulation is finished, we **reset or not the red cube position**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if done:\n",
    "    #Episode finished\n",
    "\n",
    "    #Change red cube position after n fails\n",
    "    if pixel_done:\n",
    "        nb_pixel_crash = 0\n",
    "    else:\n",
    "        nb_pixel_crash += 1 \n",
    "\n",
    "    if nb_pixel_crash == 10:\n",
    "        reset_crash = True\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **calculate training rewards**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training reward calculation\n",
    "avg_reward += running_reward\n",
    "if running_reward > best_reward:\n",
    "    best_reward = running_reward\n",
    "if running_reward < worst_reward:\n",
    "    worst_reward = running_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **plot our two curves** and **save the result** thanks to the `update function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot rewards and save the graph\n",
    "plot_reward[x] = running_reward\n",
    "plot_avg_reward[x] = avg_reward/(x+1) \n",
    "fig.update(plot_reward, x, best_reward, worst_reward, plot_avg_reward, done, pixel_done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every 100 episodes, we **save the simulation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the variables to disk.\n",
    "if x % 100 == 0 and x != 0:\n",
    "    save_path = saver.save(sess, saver_destination + \"model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is finished !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
